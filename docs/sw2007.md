# A nonparametric test of conditional independence
20/Aug/2018

## Paper Information
- [A Consistent Characteristic Function-Based Test for Conditional Independence (original paper link)](https://www.sciencedirect.com/science/article/pii/S0304407606002375)
- Liangjun Su, Halbert White
- _Journal of Econometrics_, 2007

## Abstract
Y is conditionally independent of Z given X if Pr{f(y|X,Z)= f(y|X)} =1 for all y on its support,
where f(.|.) denotes the conditional density of Y given (X,Z) or X. This paper proposes a nonparametric test of conditional independence based on the notion that two conditional distributions are equal if and only if the corresponding conditional characteristic functions are equal. We extend the test of Su and White (2005) in two directions: (1) our test is less sensitive to the choice of bandwidth sequences; (2) our test has power against deviations on the full support of the density of (X,Y, Z). We establish asymptotic normality for our test statistic under weak data dependence conditions. Simulation results suggest that the test is well behaved in finite samples. Applications to stock market data indicate that our test can reveal some interesting nonlinear dependence that a traditional linear Granger causality test fails to detect.

---

# Note
These is very important for economics or finance guys who wants to find the conditional dependency or independency, or non-causality, between factors. So questions like "Does suicides by hanging conditional on US science spending?" can be studied.
Technically speaking, the paper wants to test the following: Let X, Y and Z be random variable (r.v.), so when 

<img src="https://latex.codecogs.com/gif.latex?Y\perp&space;Z|X" title="Y\perp Z|X" />

or 

<img src="https://latex.codecogs.com/gif.latex?Pr[f(y|X,Z)=f(y|X)]=1" title="Pr[f(y|X,Z)=f(y|X)]=1" />

for all y on its support, where <img src="https://latex.codecogs.com/gif.latex?\inline&space;f(y|x,z)" title="f(y|x,z)" /> is the conditional density of Y given (X,Z) = (x,z) and <img src="https://latex.codecogs.com/gif.latex?\inline&space;f(y|x)" title="f(y|x)" /> is that of Y given X=x.

Here propose the use of conditional characteristic functions (CCF) with the following reason:
1. conditional distributions are identical i.f.f. CCF are equal
2. empirical CF (ECF) is nice
3. complementary to previous tests
4. computationally convenient
5. nonparametric


## Framework
The hypothesis are

<img src="https://latex.codecogs.com/gif.latex?\inline&space;H_0:&space;Pr\{f(y|X,Z)=f(y|X)\}=1,&space;\forall&space;y&space;\in&space;\mathbb{R}^{d_2}&space;\\&space;H1:Pr\{f(y|X,Z)=f(y|X)\}<1,&space;\text{for&space;some&space;}&space;y&space;\in&space;\mathbb{R}^{d_2}" title="H_0: Pr\{f(y|X,Z)=f(y|X)\}=1, \forall y \in \mathbb{R}^{d_2} \\ H1:Pr\{f(y|X,Z)=f(y|X)\}<1, \text{for some } y \in \mathbb{R}^{d_2}" />

Now define the difference between the CCFs, <img src="https://latex.codecogs.com/gif.latex?\inline&space;\phi_{Y|X,Z}" title="\phi_{Y|X,Z}" /> and <img src="https://latex.codecogs.com/gif.latex?\inline&space;\phi_{Y|X}" title="\phi_{Y|X}" />, as <img src="https://latex.codecogs.com/gif.latex?\inline&space;\psi" title="\psi" />, i.e.

<img src="https://latex.codecogs.com/gif.latex?\inline&space;\begin{align*}&space;\psi(u;x,z)&space;\equiv&&space;\phi_{Y|X,Z}(u;x,z)&space;-&space;\phi_{Y|X}(u;x)\\&space;=&E[\exp(iu'Y)|X=x,Z=z]&space;-&space;E[\exp(iu'Y)|X=x]&space;\end{align*}" title="\begin{align*} \psi(u;x,z) \equiv& \phi_{Y|X,Z}(u;x,z) - \phi_{Y|X}(u;x)\\ =&E[\exp(iu'Y)|X=x,Z=z] - E[\exp(iu'Y)|X=x] \end{align*}" />

This difference equalling to zero means Y and Z are independent conditional on X. Now, for a smooth function

<img src="https://latex.codecogs.com/gif.latex?\inline&space;\Gamma&space;\equiv&space;\int_S&space;\int_A&space;|&space;\int&space;\psi(u;x,z)&space;e^{i&space;\tau'&space;u}&space;dG_0(u)|^2&space;a(x,z)&space;dF(x,z)&space;dG(\tau)" title="\Gamma \equiv \int_S \int_A | \int \psi(u;x,z) e^{i \tau' u} dG_0(u)|^2 a(x,z) dF(x,z) dG(\tau)" />

, it is straightforard to develop asymptotic theory for the resulting test statistic. By introducint kernel estimators for the unknown conditional expectations and choosing regulation function a(x,z), they have a statistic

<img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;\Gamma_{3n}&space;=&&space;\frac{1}{n(n-1)^2}&space;\sum_{t_1=1}^1&space;\int&space;\left[&space;\sum_{t_2\neq&space;t_1}&space;K_{1t_1&space;t_2}\hat{f}_{2,t_2}\{H(Y_{t_2}&space;&plus;&space;\tau)&space;-&space;\hat{m}_{h_2}(X_{t_2};\tau)\}&space;\right]^2&space;dG(\tau)\\&space;\Gamma_n&space;\equiv&space;&&space;\frac{n-1}{n-2}(\Gamma_{3n}-B_n)&space;\end{align*}" title="\begin{align*} \Gamma_{3n} =& \frac{1}{n(n-1)^2} \sum_{t_1=1}^1 \int \left[ \sum_{t_2\neq t_1} K_{1t_1 t_2}\hat{f}_{2,t_2}\{H(Y_{t_2} + \tau) - \hat{m}_{h_2}(X_{t_2};\tau)\} \right]^2 dG(\tau)\\ \Gamma_n \equiv & \frac{n-1}{n-2}(\Gamma_{3n}-B_n) \end{align*}" />

which they show is **asymtotically normally distributed** under suitable assumptions.

---
[Return to home](../README.md)
